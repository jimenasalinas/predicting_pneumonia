{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enSFzSe4VZkU"
      },
      "outputs": [],
      "source": [
        "# Now that you know how to read in images, get their\n",
        "# dimensions and visualize them, let's move on to working on\n",
        "# our PyTorch dataset and COMPLETE THER EST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UZeAcRVW9kr"
      },
      "outputs": [],
      "source": [
        "# our FIRST step before we even get to building PyTorch objects\n",
        "# is actually setting up a csv file that maps the file paths to\n",
        "# their label and their category (i.e. train, val, test)\n",
        "\n",
        "# one thing to consider here is the directory structure of chest_xray.\n",
        "# within the chest_xray dir, there are three directories (train, val, test)\n",
        "# and within those, there are two subdirectories (NORMAL, PNEUMONIA)\n",
        "\n",
        "# scroll down to the __getitem___ part of our custom dataset and think\n",
        "# about how you wanna handle your file paths before you construct your\n",
        "# csv files!\n",
        "\n",
        "# you might want to create 3 csv files (one for train, one for val, one\n",
        "# for test) or you might have to just create 1 mega csv!\n",
        "# totally up to you. Whatever you decide, you will have to adjust\n",
        "# how you initialize your Dataset paramaeter (i.e. do you pass in the \n",
        "# path to the csv file? or a subset of a pandas df?)\n",
        "\n",
        "# i'm gonna let you work some Pandas magic on your own! ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BETeCabrYivE"
      },
      "outputs": [],
      "source": [
        "# Now, that we got our csv file(s) and our images, we're finally\n",
        "# ready to interact with PyTorch!\n",
        "\n",
        "# At minimum, we'll implement three objects:\n",
        "# - a custom Dataset object (PyTorch object)\n",
        "# - your image transformations (augmentations!)\n",
        "# - a DataLoader\n",
        "\n",
        "# OPTIONAL: you can also implement \n",
        "# - a custom DataModule (PyTorch Lightning object)\n",
        "#     * DataModule will use the DataLoader but the Module will\n",
        "#     * nicely encapsulate other things like data augmentation!\n",
        "#     * it's not a lot of work so I recommend it! It will make your life\n",
        "#     * for checkpoint #2!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VW64heyUiHFn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.io import read_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "IeESUPd2i0Qc",
        "outputId": "8d92bf29-f9be-4040-c44c-bb0001b564a6"
      },
      "outputs": [],
      "source": [
        "# in implemting a custom PyTorch dataset you must implement\n",
        "# three methods: __init__, __len__, and __getitem__\n",
        "\n",
        "# a Dataset is indexable, which makes allows you index (duh)\n",
        "# into your dataset, but also gives random access for \n",
        "# shuffling (which you can do yourself, or use a DataLoader, or\n",
        "# use a DataModule)\n",
        "\n",
        "# for more help: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir_path, transform=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            - csv_file (str): file path to the csv file\n",
        "            - img_dir_path: directory path to the images\n",
        "            - transform: Compose (a PyTorch Class) that strings together several\n",
        "              transform functions (e.g. data augmentation steps)\n",
        "        \"\"\"\n",
        "        self.img_labels = pd.read_csv(csv_file, skiprows=1, header=None)\n",
        "        self.img_dir = img_dir_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns: (int) length of your dataset\n",
        "        \"\"\"\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loads and returns your sample (the image and the label) at the\n",
        "        specified index\n",
        "\n",
        "        Parameter: idx (int): index of interest\n",
        "\n",
        "        Returns: image, label\n",
        "        \"\"\"\n",
        "        img_path =  os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        \n",
        "        # read the image\n",
        "        image = read_image(img_path)\n",
        "\n",
        "        # get the label\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        # if you are transforming your image (i.e. you're dealing with training data),\n",
        "        # you would do that here!\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "    \n",
        "    def count_sizes(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer, height, width = train_data[0][0].shape\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we implemented the Class, we create one object per dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = CustomImageDataset(csv_file = '../data/data_train.csv',img_dir_path = '../data')\n",
        "val_data = CustomImageDataset(csv_file = '../data/data_val.csv',img_dir_path = '../data')\n",
        "test_data = CustomImageDataset(csv_file = '../data/data_test.csv',img_dir_path = '../data')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The labels for each one of the datasets are the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    3875\n",
              "0    1341\n",
              "Name: 1, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train dataset\n",
        "train_data.img_labels.iloc[:,1].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    8\n",
              "1    8\n",
              "Name: 1, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Validation dataset\n",
        "val_data.img_labels.iloc[:,1].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    390\n",
              "0    234\n",
              "Name: 1, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test dataset\n",
        "test_data.img_labels.iloc[:,1].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5216"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbpNQLXl1Hx8"
      },
      "outputs": [],
      "source": [
        "# implementing your transformations\n",
        "\n",
        "# for additional help: https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose\n",
        "\n",
        "# for a list of transformations illustrated: \n",
        "# https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "\n",
        "# NOTE: per PyTorch, \n",
        "\"\"\"\n",
        "Most transformations accept both PIL images and tensor images,\n",
        "although some transformations are PIL-only and some are tensor-only.\n",
        "\"\"\"\n",
        "\n",
        "# therefore, you will have to experiment with what works with your image!\n",
        "# or read the documentation!\n",
        "\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transforms = T.Compose(\n",
        "    [\n",
        "        # if you are using cv2, you will need to FIRST convert\n",
        "        # the image to a Tensor. if you are using PIL to read in your image\n",
        "        # you will need to convert uit to a Tensor eventually!\n",
        "     \n",
        "        T.RandomAdjustSharpness(sharpness_factor=2),\n",
        "        T.RandomPosterize(bits=4, p=0.5)\n",
        "        # this is just an example. I randomly selected some.\n",
        "        # Choose your own more carefully! :)\n",
        "        # you will definitely want to RESIZE your image! if you don't want to\n",
        "        # decide on a size yet, you can return to resizing for checkpoint #2 when\n",
        "        # we implement our custom model!\n",
        "\n",
        "        # if you are normalizing your image, you will need to consider two things\n",
        "     \n",
        "        # 1) if you are using a pre-trained model, you will use the mean and SD\n",
        "        # of the data that model was trained on\n",
        "        # (this does not apply to us yet or ever, depending on what you do for the\n",
        "        # final part of the project)\n",
        "\n",
        "        # 2) if you are using a custom model, you will need to normalize your images\n",
        "        # based on the mean and SD of your TRAINING data\n",
        "        # and you will have to normalize your validation and your test data, too\n",
        "        # using your training data's mean and SD\n",
        "     \n",
        "        # this brings us to another good point to consider -- you might have to\n",
        "        # prepare two transformations for your datasets \n",
        "        # your augmentation transform for your training data, which will normalize\n",
        "        # (if you're doing that), distort and resize the image\n",
        "        # one that just normalizes (if you're doing that) and resizes\n",
        "        # your validation and testing data\n",
        "     \n",
        "        # LOTS TO THINK ABOUT <3 \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfG3Zebe9k3n"
      },
      "outputs": [],
      "source": [
        "# building your DataLoaders\n",
        "\n",
        "# here we can more directly see how the dataset interacts wiht the dataloader\n",
        "# the dataloader really is just an iterator. it's not very \"smart\"\n",
        "# it's not going to give you validation data just because you named it val_dataloader\n",
        "# so the distinction will need to happen when you create val_data, which means that\n",
        "# you need to either build in an mechanism internally in the CustomImageDataset to \n",
        "# parse for `valid` category inside the csv (if you are just providing the file path\n",
        "# to a mega csv) or you can pass it an already subsetted csv or df!\n",
        "\n",
        "training_data = CustomImageDataset(csv or df, img_dir_path, transforms)\n",
        "val_data = CustomImageDataset(csv or df, img_dir_path, transforms)\n",
        "test_data = CustomImageDataset(csv or df, img_dir_path, transforms)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfVf5PsFDrAW"
      },
      "outputs": [],
      "source": [
        "# you don't have to implement a DataModule for your first checkpoint\n",
        "# but you might find it helpful to revisit this for your final submission!\n",
        "\n",
        "# DataModule comes from PyTorch Lightning, which is a library that \n",
        "# streamlined, high-level interface for PyTorch. PyTorch Lightning\n",
        "# abstracts away a lot of the nitty gritty details that you have to \n",
        "# handle (such as moving data between your CPUs and GPUs, implementing\n",
        "# iteration, etc) and makes your machine learning project simpler\n",
        "\n",
        "# DataModule encapsulates the five steps involved in data processing in PyTorch:\n",
        "#   - Download / tokenize / process.\n",
        "#   - Clean and (maybe) save to disk.\n",
        "#   - Load inside Dataset.\n",
        "#   - Apply transforms (rotate, tokenize, etcâ€¦).\n",
        "#   - Wrap inside a DataLoader.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koCjLhjwDbz5"
      },
      "outputs": [],
      "source": [
        "# again, there are several methods you have to implement:\n",
        "# __init__, setup, train_dataloader, val_dataloader\n",
        "# and test_dataloader\n",
        "\n",
        "# prepare_data is a method you will commonly seen included in\n",
        "# a data module. It is only necessary if you are downloading the\n",
        "# data using your DM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YPfZnTLI275"
      },
      "outputs": [],
      "source": [
        "# WARNING: few months back, PyTorch Lightning became Lightning\n",
        "# so you will see both:\n",
        "# import ligthning as L\n",
        "# import lightning.pytorhc as pl\n",
        "# import import pytorch_lightning as pl\n",
        "\n",
        "# depending on the version of lightning or pytorch_lightning you\n",
        "# are using, all three are valid for now! but the company wants\n",
        "# people to move over to `import ligthning as L`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWwEYjvUF-Ig"
      },
      "outputs": [],
      "source": [
        "import lightning as L \n",
        "\n",
        "class OurDataModule(L.LightningDataModule):\n",
        "    def __init__(self, data_dir, batch_size, transform):\n",
        "        super().__init__()  # this is a Python thing. it ensures inheritance by the\n",
        "                            # child class (in our case, `OurDataModule` is the child class\n",
        "                            # and `L.LightningDataModule` is the parent class\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "        # these attributes will be handled by `setup`\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "    def setup(self):\n",
        "      se\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
